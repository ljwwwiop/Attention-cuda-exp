# Attention-cuda-exp
Just handcraft a few important attentions in CUDA for experimental learning.

---
## flash-attn-v1-minial
gcc >= 7.5, ubuntu 18.05, 4090 RTX GPU 24GB
b=16, head=12, seq_len=32, head_embd=64

=== profiling manual attention ===
-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                     aten::matmul         0.62%     207.000us        54.86%      18.345ms       9.172ms     104.000us         0.31%      18.513ms       9.257ms             2  
                                        aten::bmm         4.51%       1.507ms        53.69%      17.955ms       8.977ms      17.852ms        53.34%      17.852ms       8.926ms             2  
                                        aten::mul         0.25%      84.000us        25.72%       8.600ms       8.600ms       8.584ms        25.65%       8.584ms       8.584ms             1  
                                    aten::softmax         0.11%      38.000us        19.16%       6.409ms       6.409ms       5.000us         0.01%       6.284ms       6.284ms             1  
                                   aten::_softmax         0.15%      51.000us        19.05%       6.371ms       6.371ms       6.279ms        18.76%       6.279ms       6.279ms             1  
                                    aten::reshape         0.19%      62.000us         0.27%      89.000us      22.250us     298.000us         0.89%     342.000us      85.500us             4  
                               aten::_unsafe_view         0.07%      22.000us         0.07%      22.000us      11.000us     126.000us         0.38%     126.000us      63.000us             2  
                                     aten::expand         0.20%      68.000us         0.22%      72.000us      18.000us      69.000us         0.21%      89.000us      22.250us             4  
                                  aten::transpose         0.19%      65.000us         0.25%      83.000us      83.000us      66.000us         0.20%      88.000us      88.000us             1  
                                 aten::as_strided         0.07%      22.000us         0.07%      22.000us       4.400us      42.000us         0.13%      42.000us       8.400us             5  
-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 33.442ms
Self CUDA time total: 33.469ms

=== profiling minimal flash attention === 
--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                      Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
          aten::zeros_like         0.93%      24.000us        71.78%       1.857ms       1.857ms       6.000us         0.25%       1.825ms       1.825ms             1  
               aten::zero_         1.28%      33.000us        69.58%       1.800ms     900.000us       7.000us         0.29%       1.815ms     907.500us             2  
               aten::fill_         1.47%      38.000us        68.73%       1.778ms     889.000us       1.810ms        76.11%       1.810ms     905.000us             2  
                  aten::to         0.73%      19.000us        13.53%     350.000us     175.000us      11.000us         0.46%     409.000us     204.500us             2  
            aten::_to_copy         1.62%      42.000us        12.79%     331.000us     165.500us      14.000us         0.59%     398.000us     199.000us             2  
               aten::copy_         0.62%      16.000us        10.75%     278.000us     139.000us     380.000us        15.98%     380.000us     190.000us             2  
               aten::zeros         0.77%      20.000us         1.12%      29.000us      29.000us       7.000us         0.29%     133.000us     133.000us             1  
               aten::empty         0.31%       8.000us         0.31%       8.000us       4.000us     126.000us         5.30%     126.000us      63.000us             2  
                aten::full         0.93%      24.000us         1.35%      35.000us      35.000us       7.000us         0.29%      11.000us      11.000us             1  
          aten::empty_like         0.73%      19.000us         1.31%      34.000us      34.000us       4.000us         0.17%       6.000us       6.000us             1  
--------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 2.587ms
Self CUDA time total: 2.378ms

